{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlpda2ques3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaRKcYsCVSQ7",
        "colab_type": "code",
        "outputId": "829fdb7d-45e8-49ed-9148-96aebdba2e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        " \n",
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    \n",
        "    return sentences\n",
        "\n",
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        " \n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "\n",
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 1 - Read text anc split it\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5 - Offcourse, output the summarize texr\n",
        "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
        "\n",
        "# let's begin\n",
        "generate_summary( \"/content/sample_data/msft.txt\", 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "With Friday’s repo rate cut of 40 basis points, the RBI has shaved off 1.15 percentage points from the rate chart in the 58 days since the lockdown began, bringing the repo rate down to 4% and the reverse repo rate to 3.35%\n",
            "With this, it does appear that the central bank may have played out its rate cut card for now as prudence would dictate that it reserves some leverage for the future if economic conditions deteriorate even further\n",
            "In fact, there are those who believe that the latest cut may be no more than a sentiment booster as economic activity is at its nadir and there are not many investment proposals on the anvil that may benefit from the lower interest rate\n",
            "Existing borrowers may be the only beneficiaries of the rate cut at this point in time\n",
            "That said, the RBI deserves a pat on the back for listening to feedback over some of its moves initiated earlier during the lockdown\n",
            "Thus, the extension of the repayment moratorium on loans is a welcome measure.\n",
            "Indexes of top ranked_sentence order are  [(0.25865780966013024, ['Existing', 'borrowers', 'may', 'be', 'the', 'only', 'beneficiaries', 'of', 'the', 'rate', 'cut', 'at', 'this', 'point', 'in', 'time']), (0.24021090973021447, ['With', 'Friday’s', 'repo', 'rate', 'cut', 'of', '40', 'basis', 'points,', 'the', 'RBI', 'has', 'shaved', 'off', '1.15', 'percentage', 'points', 'from', 'the', 'rate', 'chart', 'in', 'the', '58', 'days', 'since', 'the', 'lockdown', 'began,', 'bringing', 'the', 'repo', 'rate', 'down', 'to', '4%', 'and', 'the', 'reverse', 'repo', 'rate', 'to', '3.35%']), (0.23013638009298684, ['In', 'fact,', 'there', 'are', 'those', 'who', 'believe', 'that', 'the', 'latest', 'cut', 'may', 'be', 'no', 'more', 'than', 'a', 'sentiment', 'booster', 'as', 'economic', 'activity', 'is', 'at', 'its', 'nadir', 'and', 'there', 'are', 'not', 'many', 'investment', 'proposals', 'on', 'the', 'anvil', 'that', 'may', 'benefit', 'from', 'the', 'lower', 'interest', 'rate']), (0.21428086109576608, ['With', 'this,', 'it', 'does', 'appear', 'that', 'the', 'central', 'bank', 'may', 'have', 'played', 'out', 'its', 'rate', 'cut', 'card', 'for', 'now', 'as', 'prudence', 'would', 'dictate', 'that', 'it', 'reserves', 'some', 'leverage', 'for', 'the', 'future', 'if', 'economic', 'conditions', 'deteriorate', 'even', 'further']), (0.05671403942090248, ['That', 'said,', 'the', 'RBI', 'deserves', 'a', 'pat', 'on', 'the', 'back', 'for', 'listening', 'to', 'feedback', 'over', 'some', 'of', 'its', 'moves', 'initiated', 'earlier', 'during', 'the', 'lockdown'])]\n",
            "Summarize Text: \n",
            " Existing borrowers may be the only beneficiaries of the rate cut at this point in time. With Friday’s repo rate cut of 40 basis points, the RBI has shaved off 1.15 percentage points from the rate chart in the 58 days since the lockdown began, bringing the repo rate down to 4% and the reverse repo rate to 3.35%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}